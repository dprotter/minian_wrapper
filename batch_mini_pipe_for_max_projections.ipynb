{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "\n",
    "import itertools as itt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import holoviews as hv\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from holoviews.operation.datashader import datashade, regrid\n",
    "from holoviews.util import Dynamic\n",
    "from IPython.core.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dpath = '/mnt/working_storage/7364_for_minian/10_02_24/split'\n",
    "# animal_ID = '7364'\n",
    "# date = '10_02'\n",
    "# file_dict = {\n",
    "#     '/home/dprotter/testmount/Protter/cohort_2_pfc_screening/dwp/7452/2024_10_11/10_56_56/final_check/My_V4_Miniscope':\n",
    "#         {'animal':7452, \"date\":'10_11'},\n",
    "#     '/home/dprotter/testmount/Protter/cohort_2_pfc_screening/dwp/7414/2024_10_11/12_06_24/final_check/My_V4_Miniscope':\n",
    "#         {'animal':7414, \"date\":'10_11'},\n",
    "#     '/home/dprotter/testmount/Protter/cohort_2_pfc_screening/dwp/7411/2024_10_10/15_54_25/final_check/My_V4_Miniscope':\n",
    "#         {'animal':7411, \"date\":'10_10'},\n",
    "#     '/home/dprotter/testmount/Protter/cohort_2_pfc_screening/dwp/7367/2024_10_10/16_47_10/expID/My_V4_Miniscope':\n",
    "#         {'animal':7367, \"date\":'10_10'},\n",
    "#     '/home/dprotter/testmount/Protter/cohort_2_pfc_screening/dwp/7354/2024_10_11/11_22_41/expID/My_V4_Miniscope':\n",
    "#         {'animal':7354, \"date\":'10_11'},\n",
    "#     '/home/dprotter/testmount/Protter/cohort_2_pfc_screening/dwp/7354/2024_10_11/11_22_41/expID/My_V4_Miniscope':\n",
    "#         {'animal':7354, \"date\":'10_11'},\n",
    "    \n",
    "# }\n",
    "\n",
    "file_dict = {\n",
    "    '/home/dprotter/testmount/Yurika/Meadow NAc Implants Cohort 5/529_Imaging_Timeline/split_video/split':\n",
    "        {'animal':529, \"date\":'10_22'},\n",
    " \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import minian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "tutorial"
    ]
   },
   "source": [
    "The following cell loads **minian** and usually should not be modified. If you encounter an `ImportError`, check that you followed the installation instructions and that `minian_path` is pointing to the right place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Set up Initial Basic Parameters#\n",
    "minian_path = \".\"\n",
    "sys.path.append(minian_path)\n",
    "from minian.cnmf import (\n",
    "    compute_AtC,\n",
    "    compute_trace,\n",
    "    get_noise_fft,\n",
    "    smooth_sig,\n",
    "    unit_merge,\n",
    "    update_spatial,\n",
    "    update_temporal,\n",
    "    update_background,\n",
    ")\n",
    "from minian.initialization import (\n",
    "    gmm_refine,\n",
    "    initA,\n",
    "    initC,\n",
    "    intensity_refine,\n",
    "    ks_refine,\n",
    "    pnr_refine,\n",
    "    seeds_init,\n",
    "    seeds_merge,\n",
    ")\n",
    "from minian.motion_correction import apply_transform, estimate_motion\n",
    "from minian.preprocessing import denoise, remove_background\n",
    "from minian.utilities import (\n",
    "    TaskAnnotation,\n",
    "    get_optimal_chk,\n",
    "    load_videos,\n",
    "    open_minian,\n",
    "    save_minian,\n",
    ")\n",
    "from minian.visualization import (\n",
    "    CNMFViewer,\n",
    "    VArrayViewer,\n",
    "    generate_videos,\n",
    "    visualize_gmm_fit,\n",
    "    visualize_motion,\n",
    "    visualize_preprocess,\n",
    "    visualize_seeds,\n",
    "    visualize_spatial_update,\n",
    "    visualize_temporal_update,\n",
    "    write_video,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "n_workers = min([int(os.getenv(\"MINIAN_NWORKERS\", 12)), 10])\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "\n",
    "hv.notebook_extension(\"bokeh\", width=100)\n",
    "\n",
    "interactive = False\n",
    "\n",
    "cluster = LocalCluster(\n",
    "n_workers=n_workers,\n",
    "memory_limit=\"12GB\",\n",
    "resources={\"MEM\": 1},\n",
    "threads_per_worker=2,\n",
    "dashboard_address=\":8787\",\n",
    ")\n",
    "annt_plugin = TaskAnnotation()\n",
    "cluster.scheduler.add_plugin(annt_plugin)\n",
    "client = Client(cluster)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video list is: ['/home/dprotter/testmount/Yurika/Meadow NAc Implants Cohort 5/529_Imaging_Timeline/split_video/split/output000.avi', '/home/dprotter/testmount/Yurika/Meadow NAc Implants Cohort 5/529_Imaging_Timeline/split_video/split/output001.avi', '/home/dprotter/testmount/Yurika/Meadow NAc Implants Cohort 5/529_Imaging_Timeline/split_video/split/output002.avi', '/home/dprotter/testmount/Yurika/Meadow NAc Implants Cohort 5/529_Imaging_Timeline/split_video/split/output003.avi', '/home/dprotter/testmount/Yurika/Meadow NAc Implants Cohort 5/529_Imaging_Timeline/split_video/split/output004.avi', '/home/dprotter/testmount/Yurika/Meadow NAc Implants Cohort 5/529_Imaging_Timeline/split_video/split/output005.avi', '/home/dprotter/testmount/Yurika/Meadow NAc Implants Cohort 5/529_Imaging_Timeline/split_video/split/output006.avi', '/home/dprotter/testmount/Yurika/Meadow NAc Implants Cohort 5/529_Imaging_Timeline/split_video/split/output007.avi', '/home/dprotter/testmount/Yurika/Meadow NAc Implants Cohort 5/529_Imaging_Timeline/split_video/split/output008.avi', '/home/dprotter/testmount/Yurika/Meadow NAc Implants Cohort 5/529_Imaging_Timeline/split_video/split/output009.avi', '/home/dprotter/testmount/Yurika/Meadow NAc Implants Cohort 5/529_Imaging_Timeline/split_video/split/output010.avi', '/home/dprotter/testmount/Yurika/Meadow NAc Implants Cohort 5/529_Imaging_Timeline/split_video/split/output011.avi']\n",
      "loading 12 videos in folder /home/dprotter/testmount/Yurika/Meadow NAc Implants Cohort 5/529_Imaging_Timeline/split_video/split\n"
     ]
    }
   ],
   "source": [
    "for path in file_dict.keys():\n",
    "    \n",
    "    dpath = os.path.abspath(path)\n",
    "    animal_ID = file_dict[path]['animal']\n",
    "    date = file_dict[path]['date']\n",
    "    \n",
    "    '''_________________________________________________________'''\n",
    "    minian_ds_path = os.path.join(dpath, \"minian\")\n",
    "    intpath = os.path.join(dpath,'minian_intermediate_2')\n",
    "    os.environ[\"MINIAN_INTERMEDIATE\"] = intpath\n",
    "    subset = dict(frame=slice(0, None))\n",
    "    subset_mc = None\n",
    "    output_size = 100\n",
    "    output_modifier = 0.4\n",
    "    \n",
    "    param_save_minian = {\n",
    "        \"dpath\": minian_ds_path,\n",
    "        \"meta_dict\": dict(session=-1, animal=-2),\n",
    "        \"overwrite\": True,\n",
    "    }\n",
    "\n",
    "    # Pre-processing Parameters#\n",
    "    param_load_videos = {\n",
    "        \"pattern\": \"[0-9]+.avi$\",\n",
    "        #\"pattern\": \".*.avi$\",\n",
    "        \"dtype\": np.uint8,\n",
    "        \"downsample\": dict(frame=1,height=1,width=1),\n",
    "        \"downsample_strategy\": \"subset\",\n",
    "    }\n",
    "    param_denoise = {\"method\": \"median\", \"ksize\": 7}\n",
    "    param_background_removal = {\"method\": \"tophat\", \"wnd\": 15}\n",
    "\n",
    "    # Motion Correction Parameters#\n",
    "    subset_mc = None\n",
    "    param_estimate_motion = {\"dim\": \"frame\"}\n",
    "\n",
    "    # Initialization Parameters#\n",
    "    param_seeds_init = {\n",
    "        \"wnd_size\": 1000,\n",
    "        \"method\": \"rolling\",\n",
    "        \"stp_size\": 500,\n",
    "        \"max_wnd\": 15,\n",
    "        \"diff_thres\": 3,\n",
    "    }\n",
    "    param_pnr_refine = {\"noise_freq\": 0.06, \"thres\": 1}\n",
    "    param_ks_refine = {\"sig\": 0.05}\n",
    "    param_seeds_merge = {\"thres_dist\": 10, \"thres_corr\": 0.8, \"noise_freq\": 0.06}\n",
    "    param_initialize = {\"thres_corr\": 0.8, \"wnd\": 10, \"noise_freq\": 0.06}\n",
    "    param_init_merge = {\"thres_corr\": 0.8}\n",
    "\n",
    "    # CNMF Parameters#\n",
    "    param_get_noise = {\"noise_range\": (0.06, 0.5)}\n",
    "    param_first_spatial = {\n",
    "        \"dl_wnd\": 10,\n",
    "        \"sparse_penal\": 0.01,\n",
    "        \"size_thres\": (25, None),\n",
    "    }\n",
    "    param_first_temporal = {\n",
    "        \"noise_freq\": 0.06,\n",
    "        \"sparse_penal\": 1,\n",
    "        \"p\": 1,\n",
    "        \"add_lag\": 20,\n",
    "        \"jac_thres\": 0.2,\n",
    "    }\n",
    "    param_first_merge = {\"thres_corr\": 0.8}\n",
    "    param_second_spatial = {\n",
    "        \"dl_wnd\": 10,\n",
    "        \"sparse_penal\": 0.01,\n",
    "        \"size_thres\": (25, None),\n",
    "    }\n",
    "    param_second_temporal = {\n",
    "        \"noise_freq\": 0.06,\n",
    "        \"sparse_penal\": 1,\n",
    "        \"p\": 1,\n",
    "        \"add_lag\": 20,\n",
    "        \"jac_thres\": 0.4,\n",
    "    }\n",
    "    '''------------------ end params -----------------------------------------------------\n",
    "    ----------------------------------------------------------------------------------------\n",
    "    --------------------------------------------------------------------------------------'''\n",
    "    \n",
    "    \n",
    "    varr = load_videos(dpath, **param_load_videos)\n",
    "    chk, _ = get_optimal_chk(varr, dtype=float)\n",
    "    \n",
    "    \n",
    "    '''----------------- save ---------------------------------'''\n",
    "    \n",
    "    varr = save_minian(\n",
    "    varr.chunk({\"frame\": chk[\"frame\"], \"height\": -1, \"width\": -1}).rename(\"varr\"),\n",
    "    intpath,\n",
    "    overwrite=True,\n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    ##is this all the glow removal?\n",
    "    varr_min = varr.min(\"frame\").compute()\n",
    "    varr_ref = varr - varr_min\n",
    "    \n",
    "    #denoise\n",
    "    param_denoise['ksize'] = 3\n",
    "    varr_ref = denoise(varr_ref, **param_denoise)\n",
    "    \n",
    "    #remove background\n",
    "    param_background_removal['wnd'] = 15\n",
    "    varr_ref = remove_background(varr_ref, **param_background_removal)\n",
    "    \n",
    "    \"---------------------save-------------------------\"\n",
    "    varr_ref = save_minian(varr_ref.rename(\"varr_ref\"), dpath=intpath, overwrite=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # define center for motion correction\n",
    "    subset_mc = {'height': slice(63.51875000000004, 526.71875, None),\n",
    "                 'width': slice(82.68124999999998, 547.08125, None)}\n",
    "    motion = estimate_motion(varr_ref.sel(subset_mc), **param_estimate_motion)\n",
    "    motion = save_minian( motion.rename(\"motion\").chunk({\"frame\": chk[\"frame\"]}), **param_save_minian)\n",
    "    hv.output(size=output_size)\n",
    "    \n",
    "    motion_out_graph = visualize_motion(motion)\n",
    "    hv.save(motion_out_graph, os.path.join(dpath, f'{animal_ID} {date} motion.png'))\n",
    "    \n",
    "    Y = apply_transform(varr_ref, motion, fill=0)\n",
    "    \n",
    "    Y_fm_chk = save_minian(Y.astype(float).rename(\"Y_fm_chk\"), intpath, overwrite=True)\n",
    "    Y_hw_chk = save_minian(\n",
    "    Y_fm_chk.rename(\"Y_hw_chk\"),\n",
    "    intpath,\n",
    "    overwrite=True,\n",
    "    chunks={\"frame\": -1, \"height\": chk[\"height\"], \"width\": chk[\"width\"]},\n",
    "    )\n",
    "    \n",
    "    max_proj_pre = varr_ref.max(\"frame\").compute().astype(np.float32)\n",
    "    max_proj_img = Y_hw_chk.max(\"frame\").compute()\n",
    "    \n",
    "    \n",
    "    #create max proj image and save it\n",
    "    im_opts = dict(\n",
    "    frame_width=800,\n",
    "    aspect=varr_ref.sizes[\"width\"] / varr_ref.sizes[\"height\"],\n",
    "    cmap=\"Viridis\",\n",
    "    colorbar=True,\n",
    "    )\n",
    "    \n",
    "    out =  (\n",
    "    regrid(\n",
    "            hv.Image(\n",
    "                max_proj_pre,\n",
    "                [\"width\", \"height\"],\n",
    "                label=\"before_mc\",\n",
    "            ).opts(**im_opts)\n",
    "        )\n",
    "        + regrid(\n",
    "            hv.Image(\n",
    "                max_proj_img.astype(np.float32),\n",
    "                [\"width\", \"height\"],\n",
    "                label=f\"after_mc {animal_ID} {date}\",\n",
    "            ).opts(**im_opts)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    hv.save(out, os.path.join(dpath, f'{animal_ID} {date}.png'))\n",
    "    \n",
    "    #write motion corrected video\n",
    "    write_video(Y_fm_chk, \"minian_mc.mov\", dpath)\n",
    "    \n",
    "client.close()\n",
    "cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "name": "pipeline.ipynb",
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
